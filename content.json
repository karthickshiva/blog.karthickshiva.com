{"pages":[{"title":"About","text":"Welcome to my blog! My name is Karthick Shiva, and I am a software developer with a passion for programming and technology. I created this blog to share my knowledge and insights on various programming topics, including web development, software engineering, and mobile app development. Whether you’re a beginner or an experienced programmer, my goal is to provide you with valuable information and resources that will help you improve your skills and stay up-to-date with the latest trends in the industry. I believe that technology is constantly evolving, and it’s important to stay informed and adapt to new changes in order to succeed in this field. Through this blog, I hope to inspire and motivate others to pursue their passion for programming and embrace the endless possibilities that technology has to offer. Thank you for visiting my blog, and I hope you find the content informative and helpful. If you have any questions or suggestions for future topics, please feel free to reach out to me.","link":"/about.html"},{"title":"Articles","text":"","link":"/articles/index.html"}],"posts":[{"title":"Dependency Injection","text":"Dependency injection is a design pattern used in software engineering that allows objects to be created with their dependencies supplied from outside sources. In other words, instead of an object creating its dependencies itself, the dependencies are “injected” into the object from an external source. The main benefits of dependency injection are: Decoupling: By injecting dependencies, objects are not tightly coupled to their dependencies, which makes them more modular and easier to test. Testability: Because dependencies can be easily replaced with mock objects, unit testing becomes easier and more effective. Reusability: Injected dependencies can be reused across multiple objects, reducing code duplication and improving maintainability. There are three main types of dependency injection: Constructor Injection: Dependencies are passed to an object’s constructor when it is created. Setter Injection: Dependencies are set on an object using setter methods. Interface Injection: Objects are required to implement a specific interface that defines the dependencies they require. Dependency injection frameworks are available in many programming languages to help automate the process of injecting dependencies. These frameworks use a combination of reflection and configuration files to automatically inject dependencies into objects at runtime. Examples of dependency injection frameworks include Spring Framework for Java and AngularJS for JavaScript. Here are some examples of dependency injection in Java: Constructor Injection:1234567891011public class UserService { private final UserRepository userRepository; public UserService(UserRepository userRepository) { this.userRepository = userRepository; } public User getUserById(int id) { return userRepository.findById(id); }} In this example, the UserService class has a dependency on the UserRepository class, which is passed to its constructor. The UserRepository object is injected into the UserService object when it is created. This allows the UserService object to use the methods of the UserRepository object without creating it itself. Setter Injection:123456789101112public class OrderService { private PaymentService paymentService; public void setPaymentService(PaymentService paymentService) { this.paymentService = paymentService; } public void processOrder(Order order) { paymentService.processPayment(order.getPayment()); // process order logic }} In this example, the OrderService class has a dependency on the PaymentService class, which is set using a setter method. The PaymentService object is injected into the OrderService object after it is created. This allows the OrderService object to use the methods of the PaymentService object without creating it itself. Interface Injection:12345678910111213141516171819202122public interface Logger { void log(String message);}public class ConsoleLogger implements Logger { public void log(String message) { System.out.println(message); }}public class UserService { private Logger logger; public void setLogger(Logger logger) { this.logger = logger; } public User getUserById(int id) { logger.log(\"Getting user by id: \" + id); // get user logic }} In this example, the UserService class has a dependency on the Logger interface, which is required to be implemented by any object that wants to be injected into the UserService object. The ConsoleLogger class implements the Logger interface and is injected into the UserService object using a setter method. This allows the UserService object to use the methods of the Logger object without creating it itself. These are just a few examples of how dependency injection can be used in Java. There are many other ways to use dependency injection, and the specific implementation depends on the needs of the application. Let’s say we have a class called “UserService” that is responsible for managing user data. This class has a dependency on a database connection to retrieve and store user data. Without dependency injection, the UserService class would have to create its own database connection object, which would tightly couple the UserService class to the database connection implementation. With dependency injection, we can pass in the database connection object as a dependency to the UserService class. This allows us to easily swap out different database connection implementations without having to modify the UserService class. For example, we could create a MySQLDatabaseConnection class and a PostgreSQLDatabaseConnection class, both implementing the same interface. We can then pass in either of these objects to the UserService class depending on which database we want to use. This makes our code more flexible and easier to maintain, as we can easily swap out dependencies without having to modify the code that uses them.","link":"/2023/04/22/Dependency-Injection/"},{"title":"Implementing Unique ID Generator","text":"A unique ID generator can be implemented using a combination of timestamp, counter, and random number. Here’s a possible implementation in Python: 123456789101112import timeimport randomclass IDGenerator: def __init__(self): self.counter = 0 def generate_id(self): timestamp = int(time.time() * 1000) # Get current timestamp in milliseconds self.counter = (self.counter + 1) % 10000 # Increment counter and wrap around random_num = random.randint(0, 999) # Generate random number between 0 and 999 return f\"{timestamp:013d}{self.counter:04d}{random_num:03d}\" In this implementation, the IDGenerator class has a counter initialized to zero. The generate_id method generates a unique ID by concatenating the current timestamp in milliseconds, a counter value that increments with each ID generation, and a random number between 0 and 999. The resulting ID is a 20-digit string in the format timestamp (13 digits) + counter (4 digits) + random number (3 digits). Here’s an example of how to use the IDGenerator class: 123generator = IDGenerator()for i in range(10): print(generator.generate_id()) This code creates an instance of the IDGenerator class and generates 10 unique IDs using the generate_id method. The output might look like this: 12345678910162798978283100000000000162798978283100000000001162798978283100000000002162798978283100000000003162798978283100000000004162798978283100000000005162798978283100000000006162798978283100000000007162798978283100000000008162798978283100000000009 This implementation generates unique IDs by combining a timestamp, a counter, and a random number, which ensures that the probability of collisions is very low. However, it is possible for collisions to occur if the same ID generator is used across multiple machines or if the counter wraps around too quickly. To further optimize the ID generator, additional measures such as using a stronger hash function or a distributed ID generation system may be necessary. Other options:There are several options to generate unique IDs, depending on the requirements of the application. Here are some common methods: UUID: A UUID (Universally Unique Identifier) is a 128-bit number that is guaranteed to be unique across time and space. UUIDs are generated using a combination of timestamp and random number, and can be represented as a string of hexadecimal digits. Timestamp: A timestamp is a value that represents the current date and time. Timestamps can be used as unique IDs if they are combined with a counter or a random number to ensure uniqueness. Counter: A counter is a value that increments with each ID generation. Counters can be used as unique IDs if they are combined with a timestamp or a random number to ensure uniqueness. Hash function: A hash function can be used to generate a unique ID from a given input. Hash functions take an input of arbitrary size and produce a fixed-size output that is unique for each input value. Snowflake ID: A Snowflake ID is a unique 64-bit integer that is generated using a combination of timestamp, machine ID, and sequence number. Snowflake IDs are used by distributed systems to generate unique IDs across multiple machines. Custom ID: A custom ID can be generated using any combination of the above methods, or by using a custom algorithm that meets the specific requirements of the application. Each of these methods has its own advantages and disadvantages, and the choice of ID generation method depends on the specific requirements of the application. For example, UUIDs are widely used because they are guaranteed to be unique, but they are relatively long and may not be suitable for some applications. On the other hand, counters are simple and efficient, but they may not be unique if multiple ID generators are used simultaneously. Auto Incremented ID:Using auto-incremented IDs as primary keys in SQL databases is a common practice and works well in many cases. However, there are some situations where this approach may not be suitable: Scalability: If the database is expected to grow very large, auto-incremented IDs may eventually overflow the maximum value of the data type used to store them. This can cause errors and require expensive database migrations. Security: Auto-incremented IDs can be predictable, which can be a security risk if they are used in URLs or other public-facing contexts. Attackers can use this predictability to guess other IDs and access sensitive data. Data privacy: In some cases, auto-incremented IDs can reveal information about the data, such as the order in which it was added to the database. This can be a privacy concern if the data contains sensitive information. Data integration: If data from multiple databases needs to be merged or integrated, auto-incremented IDs may not be unique across the different databases, leading to conflicts and errors. For these reasons, it may be necessary to use other methods to generate unique IDs, such as UUIDs or custom ID generators. These methods can provide better scalability, security, and data privacy, and can be more suitable for distributed systems or applications with complex data integration requirements. UUID:UUIDs (Universally Unique Identifiers) are widely used as unique identifiers in many applications and have several advantages, such as being guaranteed to be unique and not requiring a centralized ID generator. However, there are some situations where UUIDs may not be suitable: Size: UUIDs are relatively long, typically 32 hexadecimal digits (128 bits). This can be a problem if the IDs need to be stored in a database or transmitted over a network, as it can increase storage and bandwidth requirements. Predictability: Although UUIDs are designed to be unique, they are not completely random and can be predictable in some cases. This can be a security risk if the UUIDs are used in URLs or other public-facing contexts. Performance: Generating UUIDs can be computationally expensive, especially if they are generated in large batches or in a distributed system. This can affect the performance of the application and increase response times. Integration: If data from multiple systems needs to be merged or integrated, UUIDs may not be unique across the different systems, leading to conflicts and errors. For these reasons, it may be necessary to use other methods to generate unique IDs, such as custom ID generators or other types of UUIDs (such as ULIDs or Flake IDs) that address some of the limitations of standard UUIDs. The choice of ID generation method depends on the specific requirements of the application and the trade-offs between uniqueness, size, predictability, and performance. Snowflake ID:Snowflake ID is a unique 64-bit integer that is generated using a combination of timestamp, machine ID, and sequence number. Snowflake IDs are used by distributed systems to generate unique IDs across multiple machines. Here’s an example of how Snowflake ID is generated: Let’s assume that we have a distributed system with multiple machines. Each machine has a unique ID, which is a 10-bit integer. The current timestamp in milliseconds is 41 bits long. The sequence number is a 12-bit integer that increments with each ID generation on the same machine. To generate a Snowflake ID, we can concatenate these three values into a 64-bit integer in the following order: The first 41 bits represent the current timestamp in milliseconds. The next 10 bits represent the machine ID. The last 12 bits represent the sequence number. Here’s an example of how a Snowflake ID might look like: 1110011001101001110101011110010011101001110000000000000000000000 (64 bits) In this example, the first 41 bits represent the timestamp, which is equivalent to the value 1630055836000 in milliseconds. The next 10 bits represent the machine ID, which could be any value between 0 and 1023. The last 12 bits represent the sequence number, which could be any value between 0 and 4095. By using a combination of timestamp, machine ID, and sequence number, Snowflake IDs can be generated with a high degree of uniqueness and can be used to generate IDs across multiple machines in a distributed system. Here’s an implementation of the Snowflake method for generating unique IDs in Python: 123456789101112131415161718192021222324252627282930313233343536373839import timeclass SnowflakeGenerator: def __init__(self, datacenter_id, worker_id): self.twepoch = 1288834974657 self.datacenter_id = datacenter_id self.worker_id = worker_id self.sequence = 0 self.sequence_bits = 12 self.worker_id_bits = 5 self.datacenter_id_bits = 5 self.max_worker_id = -1 ^ (-1 &lt;&lt; self.worker_id_bits) self.max_datacenter_id = -1 ^ (-1 &lt;&lt; self.datacenter_id_bits) self.sequence_mask = -1 ^ (-1 &lt;&lt; self.sequence_bits) self.worker_id_shift = self.sequence_bits self.datacenter_id_shift = self.sequence_bits + self.worker_id_bits self.timestamp_shift = self.sequence_bits + self.worker_id_bits + self.datacenter_id_bits def _generate_timestamp(self): return int(time.time() * 1000 - self.twepoch) def _next_sequence(self): self.sequence = (self.sequence + 1) &amp; self.sequence_mask if self.sequence == 0: raise Exception(\"Sequence overflow\") def generate_id(self): timestamp = self._generate_timestamp() if timestamp &lt; self.last_timestamp: raise Exception(\"Clock moved backwards\") if timestamp == self.last_timestamp: self._next_sequence() else: self.sequence = 0 self.last_timestamp = timestamp return ((timestamp &lt;&lt; self.timestamp_shift) | (self.datacenter_id &lt;&lt; self.datacenter_id_shift) | (self.worker_id &lt;&lt; self.worker_id_shift) | self.sequence) Here’s how you can use this class to generate unique IDs: 123generator = SnowflakeGenerator(datacenter_id=1, worker_id=1)unique_id = generator.generate_id()print(unique_id) This will output a unique ID that is generated using the Snowflake method. You can change the datacenter_id and worker_id values to generate IDs that are unique to your specific environment. The code is an implementation of the Snowflake method for generating unique IDs in Python. The SnowflakeGenerator class has the following attributes: twepoch: This is the timestamp of the Snowflake epoch, which is January 1, 2010 in milliseconds. It is used to calculate the timestamp portion of the generated ID. datacenter_id: This is a unique identifier for the datacenter that the ID is being generated in. worker_id: This is a unique identifier for the worker that is generating the ID. sequence: This is a counter that is used to ensure that IDs generated within the same millisecond are unique. sequence_bits: This is the number of bits used to represent the sequence number. worker_id_bits: This is the number of bits used to represent the worker ID. datacenter_id_bits: This is the number of bits used to represent the datacenter ID. max_worker_id: This is the maximum value that the worker ID can be. max_datacenter_id: This is the maximum value that the datacenter ID can be. sequence_mask: This is a bitmask that is used to extract the sequence number from the generated ID. worker_id_shift: This is the number of bits to shift the worker ID to the left before combining it with the other parts of the ID. datacenter_id_shift: This is the number of bits to shift the datacenter ID to the left before combining it with the other parts of the ID. timestamp_shift: This is the number of bits to shift the timestamp to the left before combining it with the other parts of the ID. The SnowflakeGenerator class has the following methods: _generate_timestamp(): This method generates the timestamp portion of the ID by subtracting the Snowflake epoch from the current time in milliseconds. _next_sequence(): This method increments the sequence number and handles sequence number overflow. generate_id(): This method generates a unique ID using the Snowflake method. It combines the timestamp, datacenter ID, worker ID, and sequence number to create a 64-bit ID. To use the SnowflakeGenerator class, you can create an instance of the class with a unique datacenter ID and worker ID, and then call the generate_id() method to generate a new ID. The generated ID will be unique to your specific environment. Note:The Snowflake method was originally developed by Twitter to generate unique IDs for their distributed systems. They chose January 1, 2010 as the epoch for their implementation of the Snowflake method because it was a recent date at the time and it allowed for a larger range of timestamps than if they had chosen an earlier epoch. In the Snowflake method, the timestamp portion of the ID is calculated by subtracting the epoch time from the current time in milliseconds. By choosing a more recent epoch time, the timestamp portion of the ID can be represented using fewer bits, which allows for a larger range of timestamps to be represented in the ID. It’s worth noting that the choice of epoch time is somewhat arbitrary and can be adjusted to suit the needs of a particular system. However, it’s important to choose an epoch time that allows for a sufficient range of timestamps to be represented in the ID, while also ensuring that the timestamp portion of the ID doesn’t take up too many bits and reduce the number of bits available for other parts of the ID (such as the worker ID and sequence number).","link":"/2023/04/22/Implementing-Unique-ID-Generator/"},{"title":"Using Threading to Print Odd and Even Numbers in Order","text":"In this blog post, we’ll explore how to use threading in Java to print odd and even numbers in order. Threading is a powerful technique that allows us to execute multiple threads of code concurrently, which can be useful for a wide variety of applications, including parallel processing, network programming, and more. In this example, we’ll use threading to print a sequence of odd and even numbers in order. We’ll start by creating two threads, one for printing odd numbers and one for printing even numbers. Each thread will execute a loop that prints the appropriate numbers, and we’ll use a synchronization primitive called a semaphore to ensure that the threads execute in the correct order. By the end of this blog post, you’ll have a better understanding of how to use threading in Java to execute concurrent tasks. We’re going to discuss about two major methods to implement this. Using synchronized method:In Java, the synchronized keyword is used to create synchronized methods, which are methods that can be accessed by only one thread at a time. When a thread invokes a synchronized method, it acquires a lock on the object that the method is called on, and no other thread can access the synchronized method on that object until the lock is released. Here’s a sample Java code that creates two separate threads to print odd and even numbers: 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class OddEvenPrinter { private final int MAX_VALUE = 10; private int currentValue = 1; public static void main(String[] args) { OddEvenPrinter printer = new OddEvenPrinter(); Thread oddThread = new Thread(printer::printOdd, \"Odd\"); Thread evenThread = new Thread(printer::printEven, \"Even\"); oddThread.start(); evenThread.start(); } public synchronized void printOdd() { while (currentValue &lt;= MAX_VALUE) { if (currentValue % 2 != 0) { System.out.println(Thread.currentThread().getName() + \": \" + currentValue); currentValue++; notify(); } else { try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } public synchronized void printEven() { while (currentValue &lt;= MAX_VALUE) { if (currentValue % 2 == 0) { System.out.println(Thread.currentThread().getName() + \": \" + currentValue); currentValue++; notify(); } else { try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } }} This code should print the following output: 12345678910Odd: 1Even: 2Odd: 3Even: 4Odd: 5Even: 6Odd: 7Even: 8Odd: 9Even: 10 In this code, we define a OddEvenPrinter class that has a MAX_VALUE constant that specifies the maximum number to print, and a currentValue variable that keeps track of the current number to print. We create two separate threads, one for printing odd numbers and one for printing even numbers, using the Thread class and lambda expressions. The printOdd() and printEven() methods use a synchronized block to ensure that only one thread can access the shared currentValue variable at a time. Within each method, we use a while loop to print odd and even numbers, respectively. If the current value is odd and the current thread is the odd thread, we print the current value and increment the currentValue variable, and then notify the other thread to wake up. If the current value is even and the current thread is the even thread, we print the current value and increment the currentValue variable, and then notify the other thread to wake up. Otherwise, we wait for the other thread to notify us. By the end of this code, you should have two separate threads that print odd and even numbers in order. Using Semaphores:Semaphores are a synchronization mechanism that is used to control access to a shared resource in a concurrent system. They were first introduced by Edsger Dijkstra in 1965. A semaphore is essentially a counter that is associated with a shared resource. The counter can be incremented or decremented by threads that wish to access the shared resource. When the counter is greater than zero, the resource is available for use. When the counter is zero, the resource is unavailable and threads that wish to access it must wait until it becomes available. In Java, the Semaphore class is provided as part of the java.util.concurrent package. It provides methods for acquiring and releasing permits, which are equivalent to incrementing and decrementing the counter associated with the semaphore. Semaphores can be used in conjunction with other synchronization mechanisms such as locks and condition variables to implement more complex synchronization patterns. Here’s a sample Java code that uses Semaphores to print odd and even numbers in order: 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.concurrent.Semaphore;public class OddEvenPrinter { private final int MAX_VALUE = 10; private int currentValue = 1; private Semaphore oddSemaphore = new Semaphore(1); private Semaphore evenSemaphore = new Semaphore(0); public static void main(String[] args) { OddEvenPrinter printer = new OddEvenPrinter(); Thread oddThread = new Thread(printer::printOdd, \"Odd\"); Thread evenThread = new Thread(printer::printEven, \"Even\"); oddThread.start(); evenThread.start(); } public void printOdd() { while (currentValue &lt;= MAX_VALUE) { try { oddSemaphore.acquire(); System.out.println(Thread.currentThread().getName() + \": \" + currentValue); currentValue++; evenSemaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } } } public void printEven() { while (currentValue &lt;= MAX_VALUE) { try { evenSemaphore.acquire(); System.out.println(Thread.currentThread().getName() + \": \" + currentValue); currentValue++; oddSemaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } } }} In this code, we define a OddEvenPrinter class that has a MAX_VALUE constant that specifies the maximum number to print, and a currentValue variable that keeps track of the current number to print. We create two Semaphore objects, oddSemaphore and evenSemaphore, that are used to synchronize access to the shared currentValue variable. The oddSemaphore is initialized with a permit count of 1, and the evenSemaphore is initialized with a permit count of 0. We create two separate threads, one for printing odd numbers and one for printing even numbers, using the Thread class and lambda expressions. The printOdd() and printEven() methods use the acquire() and release() methods of the Semaphore class to ensure that only one thread can access the shared currentValue variable at a time. Within each method, we use a while loop to print odd and even numbers, respectively. If the current value is odd and the current thread is the odd thread, we acquire a permit from the oddSemaphore, print the current value, increment the currentValue variable, and release a permit to the evenSemaphore. If the current value is even and the current thread is the even thread, we acquire a permit from the evenSemaphore, print the current value, increment the currentValue variable, and release a permit to the oddSemaphore. By the end of this code, you should have two separate threads that print odd and even numbers in order using Semaphores. synchronized vs Semaphore:In terms of performance, Semaphores are generally faster and more efficient than synchronized methods for managing concurrency in Java. This is because Semaphores involve less overhead than synchronized methods, and they allow for more fine-grained control over access to shared resources. For this problem, both approaches (synchronized methods and Semaphores) are viable solutions and will produce correct results. However, since Semaphores are more efficient than synchronized methods, using Semaphores would be the better choice for this problem in terms of performance. In the Semaphore implementation of the Odd Even problem, we use two Semaphores to control access to the shared currentValue variable. The oddSemaphore is initialized with a permit count of 1, and the evenSemaphore is initialized with a permit count of 0. This allows us to ensure that only one thread can access the shared currentValue variable at a time, and that the threads take turns printing odd and even numbers. Overall, using Semaphores is a good choice for managing concurrency in Java applications, especially when performance is a concern. However, it’s important to note that Semaphores can be more difficult to use correctly than synchronized methods, and they require more careful design and testing to ensure that they work as intended.","link":"/2023/04/22/Using-Threading-to-Print-Odd-and-Even-Numbers-in-Order/"},{"title":"Hello World","text":"Hello and welcome to my new blog! My name is Karthick Shiva and I’m a software developer with a passion for all things technical. I’ve been working in the field for several years now, and I’ve had the opportunity to work on a wide variety of subjects across different domains. I’ve always been interested in sharing my knowledge and experiences with others, which is why I decided to start this blog. Here, I plan to write about a range of technical topics that I find interesting, from programming languages and frameworks to software architecture and design patterns. My goal with this blog is to provide valuable insights and practical advice to fellow developers and anyone else who is interested in technology. Whether you’re a seasoned pro or just starting out, I hope you’ll find something useful and informative here. In addition to writing about technical topics, I also plan to share my thoughts on industry trends, news, and events. I believe that staying up-to-date on the latest developments in the field is essential for any developer, and I hope to provide a fresh perspective on the topics that matter most. So, if you’re interested in learning more about software development, technology, and the industry as a whole, I invite you to join me on this journey. I’m excited to share my knowledge and experiences with you, and I look forward to hearing your thoughts and feedback along the way. Thanks for reading, and stay tuned for more posts to come!","link":"/2023/04/22/hello-world/"},{"title":"From Shipping Containers to Kubernetes: A Brief History of Containerization","text":"Containerization has come a long way since the days of shipping containers. In the world of technology, containerization has become a popular way to package and deploy applications. One of the most popular containerization platforms is Kubernetes. In this post, we’ll take a look at the history of containerization and how it has evolved to become the powerful platform that is Kubernetes. The Early Days of ContainerizationThe concept of containerization dates back to the 1950s, when shipping companies were looking for a way to transport goods more efficiently. The shipping industry developed standardized containers that could be easily loaded onto ships, trains, and trucks. This made it easier to transport goods across long distances and reduced the cost of shipping. In the 1970s, the concept of containerization was applied to the world of computing. The idea was to create a standardized way to package and deploy software applications. This would make it easier to move applications between different environments, such as development, testing, and production. The Rise of VirtualizationIn the 1990s, virtualization became a popular way to package and deploy applications. Virtualization allowed multiple applications to run on a single server, making it more efficient and cost-effective. However, virtualization had its drawbacks. It was resource-intensive and required a lot of overhead. The Birth of DockerIn 2013, Docker was introduced as a new way to package and deploy applications. Docker was built on top of the Linux container technology and provided a way to package applications in a lightweight and portable container. Docker quickly became popular and was adopted by many companies. The Emergence of KubernetesAs more companies started to use Docker, they realized that managing containers at scale was a challenge. This led to the development of Kubernetes, an open-source container orchestration platform. Kubernetes was designed to automate the deployment, scaling, and management of containerized applications. Kubernetes provides a way to manage and orchestrate containers across multiple hosts, making it easier to deploy and manage applications at scale. Kubernetes provides a declarative API that allows you to define the desired state of your application, and it takes care of the rest. Kubernetes ExplainedSuppose you have a web application that consists of multiple microservices. Each microservice is packaged in a Docker container and runs on a separate server. You want to deploy this application to a Kubernetes cluster and manage it using Kubernetes. First, you would create a Kubernetes deployment that defines the desired state of your application. The deployment would specify the number of replicas for each microservice, the Docker image to use, and any other configuration options. Next, you would create a Kubernetes service that exposes your application to the outside world. The service would provide a stable IP address and DNS name for your application, and it would load balance traffic across the replicas of each microservice. Once you have created the deployment and service, Kubernetes takes care of the rest. Kubernetes monitors the state of your application and ensures that the actual state matches the desired state. If a container fails, Kubernetes automatically restarts it. If a server goes down, Kubernetes automatically reschedules the containers on a different server. Kubernetes also provides a way to scale your application up or down based on demand. You can manually scale your application by updating the number of replicas in the deployment, or you can use Kubernetes’ autoscaling feature to automatically scale your application based on CPU usage, memory usage, or custom metrics. Kubernetes also provides a way to manage application updates and rollbacks. With Kubernetes, you can deploy new versions of your application without downtime. If something goes wrong, you can easily roll back to the previous version. Real Life Solutions with KubernetesKubernetes has become the de facto standard for container orchestration, and it’s used by many companies, including Airbnb, Spotify, and Lyft. These companies use Kubernetes to manage their applications at scale and provide a reliable and scalable service to their users. If you’re interested in using Kubernetes, there are many resources available to help you get started. The Kubernetes documentation is a great place to start, and there are many tutorials and courses available online. You can also use managed Kubernetes services like Google Kubernetes Engine (GKE), Amazon Elastic Kubernetes Service (EKS), or Microsoft Azure Kubernetes Service (AKS) to make it easier to deploy and manage your applications. Containerization has come a long way since the days of shipping containers. Kubernetes has become a powerful platform that can help businesses manage their applications at scale. If you’re looking to manage your applications more efficiently, Kubernetes is definitely worth considering.","link":"/2023/04/24/from-shipping-containers-to-kubernetes-a-brief-history-of-containerization/"},{"title":"Unleashing the Cloud: A Historical Odyssey of Cloud Storage","text":"In the ever-evolving landscape of technology, few innovations have revolutionized the way we store and manage data like the advent of cloud storage. The history of cloud storage is a fascinating journey that spans several decades, marked by groundbreaking developments, technological leaps, and the relentless pursuit of efficiency. Let’s embark on a historical odyssey to explore the evolution of cloud storage. The Early Days - Inception of a Digital RevolutionIn the not-so-distant past, during an era when computers were colossal and the internet was in its infancy, visionary minds began conceiving a concept that would reshape the landscape of data storage and sharing. This marks the commencement of a profound journey that has significantly influenced the way we manage and exchange digital information. Picture a time when computers communicated like discreet agents, sending encrypted messages to one another through concealed channels. These messages were akin to coded letters, and deciphering them required a close physical proximity between the communicating computers. However, the question arose: What if these computing entities could transcend spatial constraints and share information remotely? This was the nascent idea that would eventually evolve into the concept of cloud storage. In the early days, the notion of cloud storage was akin to an unwritten narrative awaiting its chapters. The aspiration was to establish a distinctive realm, a virtual haven where computers could transfer data irrespective of geographic limitations. It was an aspiration to liberate information from the shackles of physical space, allowing it to traverse freely, much like the wind carries whispers across expansive landscapes. The trailblazers of cloud storage during this epoch were akin to technological sorcerers wielding colossal machines. They commenced the arduous task of mapping out the uncharted territories of these digital heavens. The vision was to create an environment where individuals, regardless of their location, could access a communal space to safeguard their digital assets securely. The dream transcended the mere exchange of data between computers; it envisioned a space where people could archive memories, cultivate ideas, and preserve creations. It was a glimpse into a future where the restrictions of physical storage would dissolve, ushering in a new era of limitless possibilities for creativity and collaboration. As the dream of cloud storage began taking tangible form, the pioneers encountered a labyrinth of challenges and enigmas. How could they materialize this vision? How could they construct a space that was not only secure but also universally accessible? These were the intricate questions that fueled their intellectual curiosity and determination. Little did they foresee that this dream would metamorphose into reality, fundamentally altering the dynamics of our digital existence. The early days of cloud storage were analogous to the opening chapter of a sweeping saga, with numerous compelling chapters poised to unfold. The journey had just commenced, and the allure of a virtual sanctuary in the clouds held the promise of captivating minds for generations to come. UserNow write the chapter 2 in the same styleChatGPTChapter 2: Dot-Com Magic - Unveiling the Potential Fast forward to the late 1990s, a period marked by the Dot-Com Boom, where the internet was transforming into a global phenomenon. During this epoch, the idea of cloud storage began to gain momentum, and tech visionaries set out to harness the power of distributed computing on an unprecedented scale. The world was witnessing the rise of the internet, a virtual realm where possibilities seemed endless. Against this backdrop, brilliant minds started contemplating how they could leverage this expansive network to enable computers to communicate and collaborate more seamlessly. The question that lingered was, “What if the internet could serve as a conduit for computers to exchange information more efficiently than ever before?” Companies and innovators began experimenting with a novel concept known as Software as a Service (SaaS). In 1999, Salesforce emerged as a trailblazer in this arena, introducing a paradigm shift in how software applications were delivered and accessed. This marked the dawn of a new era, where businesses could utilize applications over the internet rather than relying on traditional local installations. This era of Dot-Com Magic laid the groundwork for the transformative potential of the cloud. The visionaries behind this movement envisioned a future where computing resources could be distributed, shared, and accessed remotely. The concept of cloud computing was taking shape, and the prospect of a digital landscape unbound by physical constraints was becoming increasingly tangible. During this time, the dream of cloud storage expanded beyond the confines of a select few. It became a democratized vision, with the goal of making these advanced computing capabilities accessible to businesses and individuals alike. The cloud was no longer just a concept; it was becoming a powerful force that promised to reshape the way we interacted with technology. The Dot-Com Boom set the stage for the unveiling of the cloud’s potential. Companies were exploring ways to make computing resources more scalable, efficient, and cost-effective. The idea of a shared space in the digital realm, where data and applications could transcend geographical boundaries, was gaining momentum, paving the way for the next chapter in the saga of cloud storage. Little did the world know that this Dot-Com Magic was merely the prelude to a digital revolution that would redefine the landscape of computing and communication. As the curtain rose on the next act, the stage was set for even more incredible innovations, shaping the trajectory of cloud storage for years to come.","link":"/2024/01/28/unleashing-the-cloud-a-historical-odyssey-of-cloud-storage/"},{"title":"Collision, Randomization and Welzl's Algorithm","text":"Have you ever played a 3D video game and wondered how the game engine detects collisions between objects? I recently found myself thinking about this while playing a popular racing game. As I was racing my car around the track, I couldn’t help but wonder how the game engine was able to detect collisions between my car and the other cars on the track. After doing some research, I learned that one of the ways that game engines detect collisions is by using the minimum enclosing sphere algorithm. This algorithm is used to find the smallest sphere that encloses a set of points in 3D space, which is useful in detecting collisions between objects. In the game I was playing, each car was represented by a 3D model, which was made up of a large number of points in 3D space. The game engine used the minimum enclosing sphere algorithm to calculate the minimum enclosing sphere of each car’s 3D model. By doing this, the game engine was able to determine if the minimum enclosing spheres of two cars intersected, indicating a collision. I was fascinated by this and started thinking about other applications of the minimum enclosing sphere algorithm. I realized that it could be used in various real-life simulations, such as simulations of fluid dynamics and molecular dynamics. In these simulations, the algorithm could be used to detect collisions between particles or fluid elements, which could help to simulate the behavior of fluids or molecules in real-world applications. Minimum Enclosing Circle: The minimum enclosing circle problem involves finding the smallest circle that encloses a set of points in a 2D plane. This problem can be solved using a similar approach to the minimum enclosing sphere algorithm, but with some modifications to account for the reduced dimensionality. Feeling inspired by the idea of the minimum enclosing circle problem, I decided to try and solve it myself. I thought to myself, “how hard could it be to find the smallest circle that encloses a set of points in a 2D plane?” I started by sketching out some points on a piece of paper and drawing circles around them. I quickly realized that this was not going to work, as it was difficult to determine which circle was the smallest. I needed a more systematic approach. Next, I tried to come up with a naive solution. I thought about selecting two points from the set of points and finding the distance between them. I could then draw a circle with a radius equal to half the distance between the two points. This circle would definitely enclose the two points, but it may not enclose all the other points in the set. I then thought about selecting a third point and finding the circle that passes through all three points. This circle would definitely enclose the three points, but it may not be the smallest circle that encloses all the points in the set. I decided to try a brute force algorithm to solve the minimum enclosing circle problem. While brute force algorithms are not always the most efficient, they can be useful in certain situations, especially when dealing with small sets of points. My brute force algorithm involved checking every possible circle that could be drawn around the set of points. I started by selecting three points from the set and finding the smallest circle that encloses them. I then added one point at a time and checked if the circle still enclosed all the points. If it did, then I continued adding points until all the points in the set were included. If not, then I discarded the circle and started again with a different set of three points. While this algorithm was not the most efficient, it was a valid solution to the problem. It guaranteed that the smallest possible circle that encloses all the points in the set would be found. However, it was not practical for larger sets of points, as the number of possible circles to check would become prohibitively large. Welzl’s algorithm:Since my brute force algorithm was not practical for larger sets of points, I did some research to see if there were more efficient algorithms available for solving the minimum enclosing circle problem. To my surprise, I discovered that the problem had once been a hot research topic and that many algorithms had been developed to solve it. As I delved deeper into the research, I discovered that one of the most popular algorithms for solving the minimum enclosing circle problem was the Welzl’s algorithm. This algorithm involved selecting points one at a time and finding the minimum enclosing circle that included all the previously selected points. The Welzl’s algorithm was much more efficient than my brute force algorithm and could handle larger sets of points. It was also more accurate, as it guaranteed that the smallest possible circle that encloses all the points in the set would be found. The algorithm goes as follows: 123456789101112131415Algorithm: Welzl's Algorithm for Minimum Enclosing CircleInput: A set of n points P in a 2D planeOutput: The minimum enclosing circle that encloses all the points in P1. if |P| = 1, return a circle with radius 0 centered at the only point in P.2. if |P| = 2, return the circle with diameter defined by the two points in P.3. Randomly shuffle the points in P.4. Let R be the set of points chosen so far.5. Let D be the minimum enclosing circle that encloses the points in R.6. For each point p in P \\ R: a. If p is inside D, continue to the next point. b. Add p to R. c. Recursively call the algorithm on the set of points R and update D.7. Return the minimum enclosing circle D that encloses all the points in P. Randomization:Before diving into the implementation of the Welzl’s algorithm, it’s worth noting the importance of random shuffling in the algorithm. The algorithm shuffles the points randomly before selecting them, which makes the algorithm randomized. Randomness is a pretty cool concept, don’t you think? It’s like the universe is playing dice with us and we’re just trying to figure out the rules of the game. But did you know that randomness can actually help us optimize problems? It’s true! By shuffling the points randomly, the Welzl’s algorithm is able to explore different orders of points and find the one that leads to the most efficient and accurate solution. This is especially important when dealing with large sets of points, where the number of possible orders is large and the algorithm can benefit from the added randomness. Did you also know that randomness can be used to optimize other algorithms too? For example, Monte Carlo simulations use random numbers to simulate the behavior of a system and estimate the probability of certain outcomes. This is super useful in fields like finance, engineering, and physics, where it’s hard to simulate a system using deterministic algorithms. Randomness is even used in sorting algorithms, like randomized quicksort, to avoid worst-case scenarios. And in cryptography, randomized primality testing is used to determine whether a given number is prime or composite. It’s amazing how randomness can be applied in so many different ways to make algorithms more efficient and accurate. It just goes to show that sometimes we need to embrace the chaos to find the best solutions. Implementation:After learning about the Welzl’s algorithm for minimum enclosing circle, I was excited to implement it and see it in action. I decided to create a mini project to demonstrate the algorithm and its various applications. Despite the challenges, I was determined to implement the Welzl’s algorithm and see it in action. I started by writing the pseudo code in paper and then translated it into JavaScript code. I created a simple GUI that allowed the user to input a set of points and see the minimum enclosing circle that encloses all the points. After an hour of coding and debugging, I finally had a working implementation of the Welzl’s algorithm. I was amazed at how quickly the algorithm was able to find the minimum enclosing circle for even large sets of points. Midpoint and circumcenter:In addition to the algorithm, we may need to revisit our high school math. Let’s revisit some high school math concepts and discuss how to find a circle that passes through two points and three points. Finding a circle that passes through two points is a relatively simple process. We can use the midpoint of the line segment connecting the two points as the center of the circle, and the distance between the two points as the radius of the circle. This circle will pass through both points. To find the midpoint of the line segment connecting two points, we can use the following formula: $$ \\text{midpoint} = \\left(\\frac{x_1 + x_2}{2}, \\frac{y_1 + y_2}{2}\\right) $$ where $(x_1, y_1)$ and $(x_2, y_2)$ are the coordinates of the two points that define the line segment. Once we have the midpoint, we can find the distance between the two points using the distance formula: $$ \\text{distance} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$ where $(x_1, y_1)$ and $(x_2, y_2)$ are the coordinates of the two points. The radius of the circle will be equal to half the distance between the two points, and the center of the circle will be the midpoint of the line segment connecting the two points. To begin with, finding a circle that passes through three points is a bit more involved than finding a circle that passes through two points. One way to do this is to use the fact that the perpendicular bisectors of the three line segments connecting the three points will intersect at the center of the circle. We can then use the distance between the center and any one of the points as the radius of the circle. Another approach to finding the circle that passes through three points is to use the inverse determinant and edge length approach. This method involves finding the circumcenter of the triangle formed by the three points and then using the distance between the circumcenter and any one of the points as the radius of the circle. To find the circumcenter of the triangle formed by the three points, we can use the following formula: $$x = \\frac{a^2(b^2 + c^2 - a^2)x_1 + b^2(a^2 + c^2 - b^2)x_2 + c^2(a^2 + b^2 - c^2)x_3}{2(a^2(b^2 + c^2 - a^2) + b^2(a^2 + c^2 - b^2) + c^2(a^2 + b^2 - c^2))}$$ $$y = \\frac{a^2(b^2 + c^2 - a^2)y_1 + b^2(a^2 + c^2 - b^2)y_2 + c^2(a^2 + b^2 - c^2)y_3}{2(a^2(b^2 + c^2 - a^2) + b^2(a^2 + c^2 - b^2) + c^2(a^2 + b^2 - c^2))}$$ where $(x_1, y_1)$, $(x_2, y_2)$, and $(x_3, y_3)$ are the coordinates of the three points, and $a$, $b$, and $c$ are the lengths of the sides of the triangle opposite the three points, respectively. Once we have the coordinates of the circumcenter, we can use the distance formula to find the radius of the circle. The distance formula is: $$distance = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$ where $(x_1, y_1)$ and $(x_2, y_2)$ are the coordinates of the two points. Using the inverse determinant and edge length approach we can find the circle that passes through three points. Demonstration:Here is my version of Welzl’s algorithm’s implementation: 1234567891011121314151617181920212223242526272829303132333435363738394041424344export function createWelZelCircle(points) { let minCircle = null; let supportSet = []; if (points.length &gt; 1) { shuffleArray(points); let p = points[0]; let totalPoints = points.length; minCircle = new Circle(p); let index = 1; supportSet.push(p); while (index &lt; totalPoints) { let pi = points[index]; if (!supportSet.some((p) =&gt; p === pi) &amp;&amp; !minCircle.contains(pi)) { let newCircle = updateCircle(supportSet, pi); if (newCircle &amp;&amp; newCircle.radius &gt; minCircle.radius) { minCircle = newCircle; index = 0; continue; } } index++; } } return minCircle;}function updateCircle(supportSet, point) { let updatedCircle = null; const supportSetSize = supportSet.length; switch (supportSetSize) { case 1: updatedCircle = updateCircleWithOnePoint(supportSet, point); break; case 2: updatedCircle = updateCircleWithTwoPoints(supportSet, point); break; case 3: updatedCircle = updateCircleWithThreePoints(supportSet, point); break; default: break; } return updatedCircle;} Here is the output: $~$ Overall, my curiosity about how collisions are detected in 3D games led me to discover the minimum enclosing sphere algorithm and its various applications in simulations and other fields. It’s amazing how video games can inspire us to learn and explore new concepts and technologies. To learn about this algorithm more: https://people.inf.ethz.ch/emo/PublFiles/SmallEnclDisk_LNCS555_91.pdf","link":"/2023/05/06/welzl-s-algorithm/"}],"tags":[{"name":"design-patterns","slug":"design-patterns","link":"/tags/design-patterns/"},{"name":"system-design","slug":"system-design","link":"/tags/system-design/"},{"name":"multi-threading","slug":"multi-threading","link":"/tags/multi-threading/"},{"name":"misc","slug":"misc","link":"/tags/misc/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"}],"categories":[{"name":"Design Patterns","slug":"design-patterns","link":"/categories/design-patterns/"},{"name":"System Design","slug":"system-design","link":"/categories/system-design/"},{"name":"Operating System","slug":"operating-system","link":"/categories/operating-system/"},{"name":"Misc","slug":"misc","link":"/categories/misc/"},{"name":"Technology","slug":"technology","link":"/categories/technology/"},{"name":"Algorithms","slug":"algorithms","link":"/categories/algorithms/"}]}